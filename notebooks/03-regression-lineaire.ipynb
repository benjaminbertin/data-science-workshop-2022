{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Régression linéaire sur un jeu de données synthétique\n",
    "\n",
    "## Jeu d'entraînement\n",
    "\n",
    "Nous considèrons un jeu d'entraînement constitué de $N$ points générés par un processus que nous contrôlons (par ex. $f(x)=2x$, ou $f(x)=e^x cos(2\\pi sin(\\pi x))$) et sujet à un bruit que nous contrôlons également.\n",
    "\n",
    "Nous commençons par importer les différentes librairies que nous allons utiliser. Nous fixons également la taille de la police de caractères pour l'affichage des graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La constante `N` représente le nombre de points générés pour le jeu d'entraînement. Le vecteur `x` contient les abscisses de chacun de ces `N` points. Il est généré en découpant en `N` intervalles réguliers le segment de nombres réels $[0.05,0.95]$. La constante `bruit` modélise la quantité de bruit ajouté à chaque point. Le vecteur `alea` contient le bruit pour chacun des `N` points. Il est généré par échantillonnage d'une __[loi de normale](https://en.wikipedia.org/wiki/Normal_distribution#Definition)__ de moyenne nulle et d'écart-type `bruit`. Cet échantillonnage est réalisé par la fonction __[numpy.random.randn](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randn.html)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20\n",
    "x=np.linspace(0.05,0.95,N)\n",
    "bruit=0.8\n",
    "alea = bruit * np.random.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous générons le vecteur d'ordonnées `y` associé aux abscisses `x` soit par un processus linéaire bruité de forme $f(x)=2x$, soit par un processus non-linéaire bruité de forme $f(x)=2x$, ou $f(x)=e^x cos(2\\pi sin(\\pi x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processus_lineaire(x):\n",
    "    return 2*x\n",
    "\n",
    "processus = processus_lineaire\n",
    "\n",
    "y = processus(x) + alea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons des fonctions pour afficher les données du jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_data():\n",
    "    plt.plot(x, y, \"o\", markersize=10, alpha=0.3, label='Entraînement')\n",
    "\n",
    "plot_title = \"N=%i, bruit=%.2f (entraînement)\"%(N,bruit)\n",
    "    \n",
    "def plot_legend():\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim([-7,7])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(plot_title)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_init():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "def plot_process(max_x):\n",
    "    xplot = np.linspace(0,max_x, 200)\n",
    "    plt.plot(xplot, processus(xplot), lw=2, label='Processus inconnu')\n",
    "\n",
    "def plot_model(clf, model_name, max_x):\n",
    "    xplot = np.linspace(0,max_x, 200)\n",
    "    plt.plot(xplot, clf.predict(xplot.reshape(-1, 1)), lw=2, label=model_name)\n",
    "\n",
    "plot_init()\n",
    "plot_train_data()\n",
    "plot_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle linéaire\n",
    "\n",
    "Nous apprenons un modèle linéaire à partir des données d'entraînement. La méthode `fit` de l'objet [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) attend en premier paramètre une matrice de données dont chaque ligne est un individu et chaque colonne est une variable. Or, nos observation `x` sont sous la forme d'un vecteur et non d'une matrice (car ici chaque individu n'est décrit que par une seule variable, son abscisse). Ainsi, nous transformons le vecteur `x` en une matrice de `N` lignes et `1` colonne grâce à la notation [`x.reshape(-1, 1)`](https://docs.scipy.org/doc/numpy/reference/constants.html#numpy.newaxis) (nous pouvons aussi utiliser [`x[:, np.newaxis]`](https://docs.scipy.org/doc/numpy/reference/constants.html#numpy.newaxis).\n",
    "\n",
    "Entrainez un modèle de régression linéaire sur ce dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez les données d'entrainement, notre processus et la régression linéaire obtenue par apprentissage sur le même graphique. Vous disposez des fonctions\n",
    "* `plot_process(max_x)` : `max_x` correspond à l'abscisse maxium de notre graphique (ici la valeur `1.2` permet mieux visualiser nos donnéées)\n",
    "* `plot_model(clf, model_name, max_x)`: `clf` correspond à l'instance de régression linéaire, `model_name` correspond au nom à afficher dans la légende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle polynomial\n",
    "\n",
    "Nous entrainons maintenant des modèles polynomiaux. Nous utilisons pour cela la classe [`sklearn.preprocessing.PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
    "\n",
    "Entrainez et afficher des modèles polynomiaux pour notre dataset avec différents degrés de polynôme (3, 6 et 12 par exemple). Pour simplifier pouvez créer un [`Pipeline scikit-learn`](https://scikit-learn.org/stable/modules/compose.html#pipeline) avec la fonction [`sklearn.pipeline.make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html). Un Pipeline est une succession d'opérations scikit-learn disposant toute d'une méthode `fit` et `predict`, vous pouvez le manipuler comme un estimateur classique scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge\n",
    "\n",
    "Nous apprenons ensuite un modèle polynomiale régularisé par la méthode _ridge_ avec différents choix pour le coefficient de régularisation.\n",
    "\n",
    "Entrainez et afficher des modèles polynomiaux de degré 12 régularisés pour notre dataset avec différents coefficients de régularisation (0.5, 0.1 et 0.01 par exemple). Ici aussi, vous pouvez utiliser la fonction [`sklearn.pipeline.make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de test\n",
    "\n",
    "Nous comparons les modèles sur un jeu de test en affichant la métrique `rmse` (root mean squared error).\n",
    "\n",
    "La cellule suivante créée un jeu de test avec du bruit à partir du processus défini au début du notebook.\n",
    "\n",
    "Appliquez différents modèles sur ce jeu de test, calculez le RMSE ([sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) avec `sqrt`), affichez vos regresseurs et les données de test (à l'aide de la fonction `plot_test_data`). Quel est le meilleur modèle ? Quel est l'impact de la régularisation sur une régression polynomiale de degré élevé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_test = 20\n",
    "max_x = 1.2\n",
    "bruit_test = bruit\n",
    "x_test=max_x * np.random.random(N_test)\n",
    "alea_test = bruit_test*np.random.randn(N_test)\n",
    "y_test = processus(x_test) + alea_test\n",
    "\n",
    "plot_title = \"N=%i, bruit=%.2f (test)\"%(N_test,bruit_test)\n",
    "\n",
    "def plot_test_data():\n",
    "    plt.plot(x_test, y_test, \"o\", markersize=10, alpha=0.3, label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pistes d'explorations\n",
    "\n",
    "Pour $N=10$, $f(x)=2x$ et un bruit nul, comparer sur le jeu d'entraînement les graphes de modèles de complexité croissante. Quel est le modèle qui s'adapte le mieux aux données ? Quel est le modèle qui fait les meilleurs prédictions ?\n",
    "\n",
    "Répéter ces expériences en modifiant les conditions, par exemple : ($N=10$, $f(x)=2x$, $bruit=1$) ou ($N=100$, $f(x)=2x$, $bruit=1$), etc.\n",
    "\n",
    "Décrire la relation entre la complexité du modèle (son nombre de paramètres), sa capacité à s'adapter aux données d'entraînement et sa capacité à prédire sur de nouvelles données.\n",
    "\n",
    "Répéter les expériences avec un processus génératif non linéaire, par exemple : $f(x)=e^x cos(2\\pi sin(\\pi x))$. Vous pouvez utiliser la fonction suivante pour remplacer le processus linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processus_non_lineaire(x):\n",
    "    return np.exp(x) * np.cos(2*np.pi*np.sin(np.pi*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorer la relation entre la complexité d'un modèle et les valeurs apprises pour ses paramètres.\n",
    "\n",
    "Exemple de code pour accéder aux valeurs des coefficient d'un modèle linéaire entraîné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model[2].steps[1][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model[2].steps[1][1].coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
