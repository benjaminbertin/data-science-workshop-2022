{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78b3d2a",
   "metadata": {},
   "source": [
    "# 11. Household power consumption\n",
    "\n",
    "Dans ce notebook nous étudions la pertinence du clustering sur une série temporelle de consommation d'électricité d'un foyer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23babf35",
   "metadata": {},
   "source": [
    "## 11.1 Chargement du dataset\n",
    "\n",
    "Chargeons notre dataset puis affichons quelques lignes et caractéristiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e364273",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = '/data/household_power_consumption.csv'\n",
    "df = pd.read_csv(dataset_url, index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ac397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c223b",
   "metadata": {},
   "source": [
    "Ce dataset contient la consommation en électricité d'un foyer toutes les minutes de 2006 à 2010.\n",
    "\n",
    "Vérifions si notre dataset contient des valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Global_active_power.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8acc08",
   "metadata": {},
   "source": [
    "Notre dataset contenant effectivement des valeurs manquantes, nous devons les remplacer. Nous appliquons simplement la fonction [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) sur le dataset avec le paramètre `method='bfill'` pour reprendre la dernière valeur horaire présente avant la valeur manquante (une méthode plus élaboré reposant sur une interpolation serait probablement utile, il faudrait aussi probablement analyser la répartition de ces valeurs manquantes comme par exemple analyser la durée des plages manquantes) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c404ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac07f2",
   "metadata": {},
   "source": [
    "## 11.2 Transformation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28f64f",
   "metadata": {},
   "source": [
    "L'objectif que nous nous fixons est de vérifier si nous pouvons mettre en évidence des profils de consommation quotidien.\n",
    "\n",
    "Commencons par créer une nouvelle dataframe contenant la somme des consommations par heure avec la méthode [`resample`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html) en précisant le paramètre `H`. Nous appliquons ensuite la méthode `sum` à la suite du resample pour calculer la consommation horaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd59208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df.resample('H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecb2eb",
   "metadata": {},
   "source": [
    "Transformons notre dataframe de consommation horaire pour que son index ne soit plus que la date du jour et qu'elle possède une colonne indiquant l'heure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly['hour'] = df_hourly.index.hour\n",
    "df_hourly.index = df_hourly.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e890a8",
   "metadata": {},
   "source": [
    "Puis nous appliquons la méthode `pivot` sur notre dataframe avec comme paramètre `columns='hour'`. Nous obtenons une dataframe contenant une ligne par jour et une colonne par heure de la journée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_hourly.pivot(columns='hour')\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679205ce",
   "metadata": {},
   "source": [
    "Les colonnes sont un multi-index qui sera génant pour l'affichage. Nous pouvons les transformer pour ne conserver que les heures (sans le premier niveau de l'index qui n'indique que `Global_active_power`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.columns = df_pivot.columns.get_level_values(1)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94b1cd",
   "metadata": {},
   "source": [
    "Vérifions si notre dataframe contient des valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ac123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pivot[df_pivot.isna().any(axis='columns')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a804d",
   "metadata": {},
   "source": [
    "Ces valeurs manquantes correspondant au premier jour des mesures, nous pouvons supprimer ce jour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e56db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_pivot.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128efa6",
   "metadata": {},
   "source": [
    "La cellule suivante permet de visualiser les consommation horaires pour tous les jours de notre dataframe (chaque tracé correspond à une journée) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c892582",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pivot.T.plot(figsize=(13,8), legend=False, color='blue', alpha=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228b050",
   "metadata": {},
   "source": [
    "## 11.3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00430137",
   "metadata": {},
   "source": [
    "Appliquons une série de K-means pour 2 à 31 clusters. Pour chaque nombre de clusters, nous stockons l'inertie et calculons le silhouette score, puis affichons l'elbow curve pour le silouhette score et l'inertie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_scores = []\n",
    "inertia = []\n",
    "n_cluster_list = np.arange(2,31).astype(int)\n",
    "\n",
    "X = df_pivot.values.copy()\n",
    "    \n",
    "# Very important to scale!\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "for n_cluster in n_cluster_list:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_cluster)\n",
    "    cluster_found = kmeans.fit_predict(X)\n",
    "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
    "    inertia.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(n_cluster_list, silhouette_scores)\n",
    "plt.title('Silhouette scores per cluster size')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(n_cluster_list, inertia)\n",
    "plt.title('Inertia per cluster size')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6d3b0f",
   "metadata": {},
   "source": [
    "L'elbow curve avec le silouhette score fait ressortir qu'il faut 3 clusters pour séparer au mieux les jours de notre dataset (nous avons un silouhette score plus élevé pour 2 clusters, mais il est préférable de mieux séparer nos données).\n",
    "\n",
    "Appliquons maintenant un K-means avec le nombre de clusters voulu et affichons le nombre de jours par cluster :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b04242",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "pd.Series(clusters).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd824859",
   "metadata": {},
   "source": [
    "Créons une nouvelle colonne sur notre dataframe pivot pour associer le numéro de cluster à chaque jour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['cluster'] = clusters\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055e8b0",
   "metadata": {},
   "source": [
    "Calculons le profil médian et moyen des jours de nos clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8aaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_median = df_pivot.groupby('cluster').median().values\n",
    "clusters_mean = df_pivot.groupby('cluster').mean().values\n",
    "# clusters_mean = sc.inverse_transform(kmeans.cluster_centers_)  # alternative using the scaler inverse transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64994cdd",
   "metadata": {},
   "source": [
    "Finalement, nous pouvons afficher les profils des jours median (ou moyen) de nos clusters ainsi que tous les jours de chaque cluster. Dans la cellule suivante, nous choisissons une palette de couleur pour nos clusters puis nous affichons chaque jour des clusters avec une forte transparence ainsi que le profil médian pour ces clusters. Pour choisir d'afficher le profil moyen, nous pouvons remplacer `clusters_median` par `clusters_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fbe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,1, figsize=(18,10))\n",
    "colors = plt.cm.jet(np.linspace(0,1,kmeans.n_clusters))\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    df_pivot[df_pivot.cluster == cluster].T.plot(\n",
    "        ax=ax, legend=False, alpha=0.01, color=colors[cluster], label= f'Cluster {cluster}'\n",
    "    )\n",
    "    plt.plot(clusters_median[cluster], color=colors[cluster], alpha=1, ls='--')\n",
    "ax.set_xticks(np.arange(1,25))\n",
    "ax.set_ylabel('kilowatts')\n",
    "ax.set_xlabel('hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4baa8b",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 11.4 Pour aller plus loin\n",
    "\n",
    "Avec 3 clusters, nous avons mis en évidence 3 profils de consommation quotidien, probablement liés à des jours travaillés, de présence (vacances, jours féries ou week-end) et d'absence (vacances ?).\n",
    "\n",
    "Pour aller plus loin, il serait utile de vérifier si notre hypothèse sur les profils moyen obtenus correspondent bien à des jours travaillés, de présence ou d'absence en utilisant le calendrier locale du dataset (les données ont été collectées en France). Vous pouvez aussi essayer de séparer les jours sur 4 clusters et d'expliquer le nouveau cluster obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66626daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
