{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Clustering\n",
    "\n",
    "Dans ce notebook nous appliquons des algorithmes de clustering sur des données synthétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons # for generating experimental data\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Création des datasets synthétiques\n",
    "\n",
    "Les fonctions `make_blobs` et apparentées permettent de créer des jeux de données synthétiques, dans notre cas des points dans un espace à deux dimensions qui respectent un ensemble de contraintes (des nuages de points, des cercles de points ...) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blobs, y_blobs = make_blobs(n_samples=5000,\n",
    "                              n_features=2,\n",
    "                              centers=3,\n",
    "                              random_state=170)\n",
    "X_circles, y_circles = make_circles(n_samples=1000,\n",
    "                                    factor=0.3,\n",
    "                                    noise=0.1)\n",
    "X_moons, y_moons = make_moons(n_samples=1000,\n",
    "                              noise=.05)\n",
    "X_varied, y_varied = make_blobs(n_samples=1000,\n",
    "                                random_state=8,\n",
    "                                cluster_std=[1.0, 2.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `plot_clusters` permet d'afficher ces datasets (et les clusters, comme nous le verrons plus loin). Utilisez cette fonction pour afficher nos différents datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, labels=None, centers=None):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.scatter(X[:,0], X[:,1], c=labels, edgecolors='k')\n",
    "    if centers is not None:\n",
    "        plt.scatter(\n",
    "            centers[:,0], \n",
    "            centers[:,1], \n",
    "            c='w', marker='x', s=5, linewidth=30\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 K-means\n",
    "\n",
    "Nous allons appliquer l'algorithme K-means sur notre dataset `X_blobs` en spécifiant que nous souhaitons obtenir 3 clusters.\n",
    "\n",
    "Créez une instance (que vous nommerez `kmeans`) de la classe [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) en spécifiant les paramètres :\n",
    "* `n_clusters = 3`\n",
    "* `n_init = 3`\n",
    "* `init = 'random'`\n",
    "* `tol = 1e-4`\n",
    "* `random_state = 170`\n",
    "* `verbose = True`\n",
    "\n",
    "En vous aidant de la documentation de cette classe sur le site de scikit-learn, décrivez l'effet de chacun des paramètres spécifiés ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appelez la méthode `fit_predict` en lui fournissant comme seul paramètre notre dataset `X_blobs` et stockez le résultat dans une variable `y_pred` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le contenu des attributs `labels_`, `cluster_centers_` et `inertia_` de `kmeans`. A quoi correspondent ces attributs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction `plot_clusters` pour afficher le résultat de ce clustering sur le dataset `X_blobs` (vous devez spécifier tous les paramètres de cette fonction) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Comportement de K-means\n",
    "\n",
    "En contraignant incrémentalement le nombre d'itération de K-means (et en fixant un `random_state` identique), nous pouvons visualiser les déplacements des centroids.\n",
    "\n",
    "Affichez le résultat d'un clustering K-means en variant le nombre d'itérations de 1 à 11 et commentez les résultats obtenus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Recherche du nombre de clusters optimal\n",
    "\n",
    "Notre jeu de données synthétique `X_blobs` contient clairement 3 clusters, mais que se passe-t'il si nous précisons un autre nombre de clusters à K-means ?\n",
    "\n",
    "Modifiez le nombre de clusters voulus et observez le résultat obtenu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une méthode usuelles pour déterminer le nombre de clusters optimum obtenus avec K-means consiste à déterminer à partir de combien de clusters l'inertie de notre clustering cesse de varier significativement.\n",
    "\n",
    "Constuisez une liste contenant l'inertie pour des clusterings de tailles croissantes de 1 à 11 (vous pouvez utiliser la fonction [`range`](https://docs.python.org/fr/3/tutorial/controlflow.html#the-range-function) de Python pour créer une boucle de tous les entiers entre 1 et 11) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante affiche l'intertie en fonction d'un nombre de clusters. Utilisez cette fonction pour afficher l'inertie de 1 à 11 clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow(clusters_sizes, inertia):\n",
    "    plt.figure(1, figsize=(15, 6))\n",
    "    plt.plot(clusters_sizes, inertia)\n",
    "    plt.title('The Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Limites de K-means\n",
    "\n",
    "K-means fonctionne correctement sur des jeux de données possédant des clusters *sphériques*, si nous appliquons cet algorithme sur nos autres jeux de données synthétiques, les résultats ne seront pas aussi convaincants.\n",
    "\n",
    "Appliquez un clustering K-means sur le dataset `X_circles` avec 2 clusters, puis affichez l'_elbow curve_ pour 1 à 21 clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une solution pour contourner cette limitation de K-means consiste à augmenter le nombre de clusters. Appliquez K-means avec 6 clusters sur `X_circles` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 DBScan\n",
    "\n",
    "Nous utilisons maintenant l'algorithme basé sur la densité DBScan sur ce même dataset. Les paramètres les plus importants pour cet algorithme sont :\n",
    "- epsilon (`eps`) qui définit la distance maximale pour considérer que deux points sont voisins\n",
    "- `min_samples` qui définit le nombre de voisins nécéssaires pour qu'un point soit considérer comme un *core point*\n",
    "\n",
    "Attention : il faut normaliser les données en entrée de DBScan avec [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "Normalisez le dataset `X_circle`, créez une instance de [`sklearn.cluster.DBSCAN`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) avec les paramètres `eps=0.2` et `min_samples=30`, appelez la méthode `fit_predict` de cette instance sur `X_circles` normalisé, puis affichez le résultat de ce clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez DBSCAN (avec `eps=0.5` et `min_samples=30`) et K-means (avec `nclusters=2`) sur le dataset `X_moons` (normalisez ce dataset pour DBSCAN). Quel est la méthode qui fournit le meilleur résultat ? Pourquoi la moins bonne n'arrive pas à regrouper nos deux arcs de cercles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Limitation de DBScan\n",
    "\n",
    "Comparez le clustering obtenu avec DBSCAN et K-means sur le dataset `X_varied`. Calculez le _silhouette_score_ avec la fonction [`sklearn.metrics.silhouette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) pour les deux clusterings. Quelle est la meilleure méthode ? Pourquoi la moins bonne méthode n'arrive pas à faire ressortir nos 3 clusters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
