{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification sur le dataset MNIST\n",
    "\n",
    "## 6.0 Régression logistique et fonction sigmoïde\n",
    "\n",
    "Le modèle de régression logistique est la composée d'une transformation linéaire du vecteur des observations et de la fonction sigmoïde.\n",
    "\n",
    "$$f_{\\mathbf{w},b} = \\frac{e^{\\mathbf{wx}+b}}{1 + e^{\\mathbf{wx}+b}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x) / (np.exp(0) + np.exp(x))\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "S = sigmoid(x)\n",
    "plt.plot(x, S, color='blue', lw=2)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$sigmoid(x)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Jeu de données MNIST\n",
    "\n",
    "Nous chargeons le jeu de données MNIST composé de $70 000$ images de chiffres en nuances de gris de 28 pixels par 28 pixels. La valeur de chaque pixel est comprise entre $0$ et $255$ et qualifie une nuance de gris. L'objectif est de prédire la valeur du chiffre ($0$ à $9$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the dataset from sklearn\n",
    "#from sklearn.datasets import fetch_openml\n",
    "#X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Loading the dataset from CSV files\n",
    "import pandas as pd\n",
    "X = pd.read_csv('/data/mnist_784_X.csv')\n",
    "y = pd.read_csv('/data/mnist_784_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions de X : \", X.shape, \" ; dimensions de y : \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons une fonction `print_digit` pour afficher un chiffre à partir de son vecteur. Vous pouvez l'utiliser en lui donnant comme paramètre un tableau numpy. Utilisez la pour afficher quelques images de notre dataset (l'attribut `.values` d'une series pandas est un tableau numpy), pensez à afficher aussi le chiffre correspondant (i.e. : la classe) du vecteur `y` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_digit(vec):\n",
    "    img = vec.values.reshape(28,28)\n",
    "    plt.imshow(img, cmap = \"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les labels sont représentés par des chaînes de caractères. Pour un traitement plus facile, transformez les en nombres entiers en utilisant la méthode [`astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) de la series `y` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpez votre dataset en un dataset d'entrainement et un dataset de test. Pour réduire le temps de calcul des entrainements suivants, vous pouvez choisir de ne prendre qu'une partie des données pour l'entrainement (30 000 images par exemple) en fournissant un paramètre entier à la fonction [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Classification binaire\n",
    "\n",
    "Pour traiter le cas de la classification binaire, nous considérons le problème de la détection du chiffre $8$. Créez deux series `y_train_8` et `y_test_8` contenant des booléens indiquant si le chiffre est un $8$ ou non :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainez un modèle de [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) en recherchant les meilleurs hyper-paramètres par validation croisée avec 3 plis (pour réduire le temps de calcul). Votre grille d'hyper-paramètres pourra se concentrer sur le coefficient de régularisation `C` que vous pouvez faire varier avec `np.logspace(-5, 5, 10)`. Puis affichez les meilleurs hyper-paramètres trouvés.\n",
    "\n",
    "Pensez à centrer et réduire vos données dans un pipeline avec la classe [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "En effet, certains algorithmes d'optimisation de la fonction de coût se comportent mieux quand les données sont standardisées. C'est en particulier le cas des algorithmes de régularisation comme _ridge_, _LASSO_ ou _elastic net_. Par exemple, __[la documentation de scikit-learn pour l'algorithme de régression logistique](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__ précise :\n",
    "\n",
    ">Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez l'exactitude (`accuracy`) d'un modèle entrainé avec ces hyper-paramètres sur le jeu d'entrainement avec une validation croisée à 10 plis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la proportion de valeur `True` dans `y_train_8` (donc la proportion de chiffre 8 dans notre dataset d'entrainement). Ce dataset est-il équilibré ? Est-ce que l'exactitude suffit à mesurer la performance d'un modèle sur ce dataset ? Pouvez-vous imaginer un modèle simple pour ce dataset ayant des performances proches du modèle entrainé avec une regression logistique ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Mesures de performance\n",
    "\n",
    "### 6.3.1 Matrice de confusion\n",
    "\n",
    "Utilisez la fonction [`sklearn.model_selection.cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) (avec 10 plis) pour récupérer les labels prédits (et non seulement un score) sur une validation croisée. Stockez le résultat dans une variable `y_train_8_pred`, ces résultats nous servirons à mesurer les performances de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) pour calculer la matrice de confusion sur ces prédictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'affichage obtenu peut-être amélioré avec un graphique, la fonction suivante permet d'afficher un tel graphique. Elle prend en paramètre les trois listes suivantes :\n",
    "* `y_true` : les vérités terrains\n",
    "* `y_pred` : les prédictions\n",
    "* `labels` : les labels à afficher (dans notre cas, vous pouvez utiliser `['non_8', '8']`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ax= plt.subplot()\n",
    "    #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Précision, Rappel, score F1\n",
    "\n",
    "Calculez et affichez la précision, le rappel et le score F1 avec les fonctions [`sklearn.metrics.precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) et [`sklearn.metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), puis concluez sur les performances du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Courbe précision / rappel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des modèles de classification retournent une probabilité d'appartenance à une classe (dans le cas binaire, une probabilité que l'individu soit de la classe $1$, ou que le chiffre soit un $8$ dans notre cas). Les métriques précédentes sont calculées pour un seuil de décision de $0.5$.\n",
    "\n",
    "Affichez une image du dataset et calculez la probabilité que ce soit un $8$ pour notre modèle en utilisant la fonction `predict_proba` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score $F_1$ privilégie les modèles avec une précision et un rappel semblables. Selon le contexte, nous pouvons préférer un modèle avec une bonne précision ou un bon rappel. Ainsi, il est intéressant de contrôler le seuil de probabilité utilisé pour prendre la décision.\n",
    "\n",
    "Pour cela, nous avons besoin de récupérer les probabilités associées à chaque individu du jeu d'entrainement. Utilisez la fonction [`sklearn.model_selection.cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) avec 10 plis et le paramètre `method=\"predict_proba\"` pour récupérer ces probabilités. Stockez le résultat dans une variable `y_train_8_scores`. Vous obtiendrez un tableau des probabilités pour les deux classes (non 8 et 8), transformez ce tableau en un tableau de probabilités pour la classe \"est un 8\" `np.array([y[1] for y in y_train_8_scores])` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons faire varier le seuil de désision pour obtenir un meilleur rappel au détriment de la précision (et inversement). Calculez d'abord la précision et le rappel pour différents seuils de décision en utilisant la fonction [`sklearn.metrics.precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante affiche un graphique des courbes de précision et rappel en fonction des seuils de décisions possibles, ses paramètres sont les mêmes que la sortie de la fonction `precision_recall_curve` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_proba(precisions, recalls, probas):\n",
    "    plt.plot(probas, precisions[:-1], \"b--\", label=\"Précision\", linewidth=2)\n",
    "    plt.plot(probas, recalls[:-1], \"g-\", label=\"Rappel\", linewidth=2)\n",
    "    plt.xlabel(\"Seuil de probabilité\", fontsize=16)\n",
    "    plt.legend(loc=\"best\", fontsize=16)\n",
    "    plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi utiliser la fonction suivante pour afficher la précision en fonction du rappel, ce qui nous permet de choisir l'un en fonction de l'autre en fonction de nos objectifs. Ses paramètres sont les précisions et les rappels calculés précédement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Rappel\", fontsize=16)\n",
    "    plt.ylabel(\"Précision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Classes multiples\n",
    "\n",
    "Entrainer un modèle _softmax_ avec régularisation _elasticnet_ sur la classification en classes multiples en recherchant les meilleurs hyper-paramètres puis en calculant les performances de ces hyper-paramètres sur le dataset d'entrainement avec une validation croisée à 10 plis.\n",
    "\n",
    "Le modèle _sortmax_ est disponible via la classe `LogisticRegression` en utilisant la valeur `multinomial` pour le paramètre `multi_class`. Pour une régularisation _elasticnet_, il faut définir le paramètre `penalty` à `l2`. Vous pouvez aussi utiliser les paramètres `solver='saga'` et `tol=0.1` pour que l'algorithme converge plus rapidement.\n",
    "\n",
    "Calculez l'exactitude de ce modèle et affichez ses prédictions pour quelques invididus de notre jeu d'entrainement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Forêt aléatoire\n",
    "\n",
    "Entrainez un modèle de forêt aléatoire sur le problème MNIST puis comparez le modèle obtenu avec le modèle _sortmax_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Evaluation du meilleur modèle sur le jeu de test\n",
    "\n",
    "Evaluez le meilleur modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
