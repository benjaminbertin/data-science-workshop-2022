{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude du jeu de données California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse exploratoire des données\n",
    "\n",
    "Dimensions de notre dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types des variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description des variables numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description des variables catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=[object]).columns:\n",
    "    counts = df[col].value_counts()\n",
    "    if len(counts) < 20:\n",
    "        print(\"\\nModalités de la variable \", col)\n",
    "        pprint.pprint(df[col].value_counts())\n",
    "    else:\n",
    "        print(\"\\nLa variable %s possède %i modalités\" % (col, len(counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des corrélations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valeurs manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boîtes à moustaches - version sns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_grid_sns(df, nb_grid_cols=3, figsize=(16,15)):\n",
    "    df_num = df.select_dtypes(include=[np.number])\n",
    "    nb_num_vars = len(df_num.columns)\n",
    "    fig, axes = plt.subplots(math.ceil(nb_num_vars/nb_grid_cols), nb_grid_cols, figsize=figsize)\n",
    "    for i, col in enumerate(df_num.columns):\n",
    "        sns.boxplot(data=df_num, x=col, ax=axes[int(i/nb_grid_cols),i%nb_grid_cols])\n",
    "    plt.show()\n",
    "boxplot_grid_sns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boîtes à moustaches - version plotly :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_grid_plotly(df, nb_grid_cols=3):\n",
    "    cols = df.select_dtypes(include=[np.number]).columns\n",
    "    fig = make_subplots(rows=math.ceil(len(cols)/nb_grid_cols), cols=nb_grid_cols)\n",
    "    for i, var in enumerate(cols):\n",
    "        fig.add_trace(\n",
    "            go.Box(y=df[var],\n",
    "            name=var),\n",
    "            row=int(i/nb_grid_cols)+1, col=i%nb_grid_cols+1\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=950,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n",
    "boxplot_grid_plotly(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogrammes avec estimation de densité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot_grid(df, nb_grid_cols=3, figsize=(16,15)):\n",
    "    df_num = df.select_dtypes(include=[np.number])\n",
    "    nb_num_vars = len(df_num.columns)\n",
    "    fig, axes = plt.subplots(math.ceil(nb_num_vars/nb_grid_cols), nb_grid_cols, figsize=figsize)\n",
    "    for i, col in enumerate(df_num.columns):\n",
    "        not_null_col = df_num[col][df_num[col].notnull()]\n",
    "        sns.histplot(not_null_col, ax=axes[int(i/nb_grid_cols),i%nb_grid_cols], kde=True)\n",
    "    plt.show()\n",
    "density_plot_grid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il y a des valeurs manquantes pour la variable `total_bedrooms`. Nous traiterons les valeurs manquantes dans la chaîne de transformation pour le pré-traitement des données.\n",
    "- Les valeurs de la cible `median_house_value` supérieures à `500000` semblent avoir subi un effet de seuil et avoir été enregistrées avec un montant associé fixé à `500000`. Il semble préférable de ne pas conserver ces enregistrements. Par ailleurs, observons qu'ils se concentrent sur des zones bien spécifiques de la Californie.\n",
    "- Les variables `total_rooms`, `total_bedrooms`, `population` et `households` sont très fortement corrélées. Il semble pertinent de rapporter le nombre de pièces et la population au nombre de foyers. De même, le nombre de chambres peut être ramené au nombre de pièces. Nous proposons d'introduire les variables `rooms_per_household`, `population_per_household` et `bedrooms_per_room`.\n",
    "- Certaines boîtes à moustaches indiqueraient un grand nombre de valeurs aberrantes. Cependant, les histogrammes avec estimateur de densité montrent que les distributions correspondantes ne sont pas normales mais asymétriques avec plus d'observations du côté des valeurs élevées.\n",
    "- Une standardisation ou normalisation sont à tester, en particulier dans le cas de modèles linéaires, car les échelles des variables sont très différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des prix de maisons médians supérieurs à 500 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['median_house_value']>500000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['500k'] = df['median_house_value']>500000\n",
    "df['500k'] = df['500k'].astype(int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.3,\n",
    "        s=df[\"population\"]/100, label=\"population\",\n",
    "        figsize=(10,8), c=\"500k\", cmap=plt.get_cmap(\"rainbow\"))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['500k']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous retenons seulement les enregistrements dont la cible ne dépasse pas `500000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['median_house_value']<=500000].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une stratégie possible pour la gestion des valeurs manquantes serait de supprimer les lignes correspondantes. Voir ci-dessous une manière de le faire. Cependant, nous préférons gérer les valeurs manquantes au sein de la chaîne de transformation qui opérera l'ensemble des pré-traitements. Ainsi, nous pouvons comparer par validation croisée différentes formes d'imputation pour la gestion des valeurs manquantes. Cette approche est également plus robuste si, pour la mise en production du modèle, d'autres variables que `total_bedrooms` ont des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['total_bedrooms'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des variables fortement corrélées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons les nouvelles variables `rooms_per_household`, `population_per_household` et `bedrooms_per_room`. Nous retirons les variables `total_rooms`, `total_bedrooms` et `population`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
    "df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']\n",
    "df['population_per_household'] = df['population'] / df['households']\n",
    "df = df.drop(columns=['total_rooms', 'total_bedrooms', 'population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que le revenu médian est corrélé positivement avec le nombre de pièces mais négativement avec la proportion de chambres à coucher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations géographiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.3,\n",
    "        s=df[\"population_per_household\"], label=\"population per household\",\n",
    "        figsize=(10,8), c=\"median_house_value\",\n",
    "        cmap=plt.get_cmap(\"rainbow\"), colorbar=True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.population_per_household > 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du jeu d'entraînement et du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=77)\n",
    "\n",
    "X_train = train.drop(\"median_house_value\", axis=1)\n",
    "y_train = train[\"median_house_value\"].copy()\n",
    "X_test = test.drop(\"median_house_value\", axis=1)\n",
    "y_test = test[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des variables\n",
    "### Classement des variables en fonction de leurs types (numériques, catégorielles, ordinales...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_num = ['longitude', 'latitude', 'housing_median_age', \n",
    "                 'households', 'median_income', \n",
    "                 'rooms_per_household', 'bedrooms_per_room', 'population_per_household' ]\n",
    "var_names_cat = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des chaînes de transformation pour la préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preparation_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, var_names_num),\n",
    "    (\"cat\", OneHotEncoder(), var_names_cat),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des modèles\n",
    "### Modèle Ridge\n",
    "#### Choix des hyper-paramètres par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"preparation\", preparation_pipeline),\n",
    "    (\"model\", Ridge(tol=0.01, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "ridge_param_grid = [\n",
    "    {\n",
    "        'model__alpha': np.logspace(-5, 5, 10),\n",
    "        'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearch_ridge = GridSearchCV(\n",
    "    ridge_pipeline, ridge_param_grid, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    ")\n",
    "gridsearch_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Meilleurs paramètres :')\n",
    "print(gridsearch_ridge.best_params_)\n",
    "\n",
    "rmse_best_ridge_model = np.sqrt(-gridsearch_ridge.best_score_)\n",
    "print('RMSE par validation croisée du meilleur modèle : ', rmse_best_ridge_model)\n",
    "\n",
    "best_ridge_model = gridsearch_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(best_ridge_model, 'california_ridge_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score par validation croisée sur le jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_scores = cross_val_score(\n",
    "    best_ridge_model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1\n",
    ")\n",
    "ridge_cv_scores = np.sqrt(-ridge_cv_scores)\n",
    "print(\n",
    "    \"Moyenne des scores : \", ridge_cv_scores.mean(),\n",
    "    \"Ecart type des scores : \", ridge_cv_scores.std()\n",
    ")\n",
    "dump(ridge_cv_scores, 'california_ridge_score.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de forêt aléatoire\n",
    "#### Choix des hyper-paramètres par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"preparation\", preparation_pipeline),\n",
    "    (\"model\", RandomForestRegressor(n_jobs=-1, n_estimators=50, random_state=77, criterion='mse'))\n",
    "])\n",
    "\n",
    "rf_param_grid = [\n",
    "    {\n",
    "        'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__min_samples_leaf': [1,3,5],\n",
    "        'model__max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearch_rf = GridSearchCV(rf_pipeline, rf_param_grid, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "gridsearch_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Meilleurs paramètres :')\n",
    "print(gridsearch_rf.best_params_)\n",
    "\n",
    "rmse_best_rf_model = np.sqrt(-gridsearch_rf.best_score_)\n",
    "print('RMSE par validation croisée du meilleur modèle : ', rmse_best_rf_model)\n",
    "\n",
    "best_rf_model = gridsearch_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_rf_model, 'california_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de l'importance des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_one_hot = list(best_rf_model.named_steps[\"preparation\"].named_transformers_['cat'].categories_[0])\n",
    "var_names_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = var_names_num + var_names_one_hot\n",
    "var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances(rf_model, var_names, figsize=(12,12)):\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    std_feature_importances = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
    "    print(sorted(zip(feature_importances, std_feature_importances, var_names), reverse=True))\n",
    "    sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "    sorted_names = [name for _ , name in sorted(zip(feature_importances, var_names), reverse=True)]\n",
    "    nb_features = len(feature_importances)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\"Importance des variables\")\n",
    "    plt.bar(range(nb_features), feature_importances[sorted_indices],\n",
    "            color=\"b\", yerr=std_feature_importances[sorted_indices], \n",
    "            align=\"center\")\n",
    "    plt.xticks(range(nb_features), sorted_names, rotation=70)\n",
    "    plt.xlim([-1, nb_features])\n",
    "    plt.show()\n",
    "feature_importances(best_rf_model.named_steps['model'], var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score par validation croisée sur le jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_scores = cross_val_score(\n",
    "    best_rf_model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1\n",
    ")\n",
    "rf_cv_scores = np.sqrt(-rf_cv_scores)\n",
    "print(\n",
    "    \"Moyenne des scores : \", rf_cv_scores.mean(),\n",
    "    \"Ecart type des scores : \", rf_cv_scores.std()\n",
    ")\n",
    "dump(rf_cv_scores, 'california_rf_score.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "axis = figure.add_subplot(111)\n",
    "plt.boxplot([ridge_cv_scores, rf_cv_scores])\n",
    "axis.set_xticklabels(['Ridge', 'Forêt aléatoire'], rotation = 45, ha=\"right\")\n",
    "axis.set_ylabel(\"Root Mean Squared Error (RMSE)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du meilleur modèle sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_pred = best_rf_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "print(\"Test RMSE : \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réutilisation d'un modèle enregistré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('california_rf_model.joblib')\n",
    "clf.predict(X_test.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
