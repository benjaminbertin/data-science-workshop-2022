{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification sur le dataset MNIST\n",
    "\n",
    "## 6.0 Régression logistique et fonction sigmoïde\n",
    "\n",
    "Le modèle de régression logistique est la composée d'une transformation linéaire du vecteur des observations et de la fonction sigmoïde.\n",
    "\n",
    "$$f_{\\mathbf{w},b} = \\frac{e^{\\mathbf{wx}+b}}{1 + e^{\\mathbf{wx}+b}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run miscellaneous.ipynb\n",
    "# https://filesender.renater.fr/?s=download&token=479c4058-ca6a-464f-ac46-4bdcf7f5ddae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x) / (np.exp(0) + np.exp(x))\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "S = sigmoid(x)\n",
    "plt.plot(x, S, color='blue', lw=2)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$sigmoid(x)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Jeu de données MNIST\n",
    "\n",
    "Nous chargeons le jeu de données MNIST composé de $70 000$ images de chiffres en nuances de gris de 28 pixels par 28 pixels. La valeur de chaque pixel est comprise entre $0$ et $255$ et qualifie une nuance de gris. L'objectif est de prédire la valeur du chiffre ($0$ à $9$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "import pandas as pd\n",
    "X = pd.read_csv('/data/mnist_784_X.csv')\n",
    "y = pd.read_csv('/data/mnist_784_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions de X : \", X.shape, \" ; dimensions de y : \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons une fonction `print_digit` pour afficher un chiffre à partir de son vecteur. Vous pouvez l'utiliser en lui donnant comme paramètre un tableau numpy. Utilisez la pour afficher quelques images de notre dataset (l'attribut `.values` d'une series pandas est un tableau numpy), pensez à afficher aussi le chiffre correspondant (i.e. : la classe) du vecteur `y` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_digit(vec):\n",
    "    img = vec.values.reshape(28,28)\n",
    "    plt.imshow(img, cmap = \"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sample_id = random.randint(0, len(X))\n",
    "print(\"X[0] :\")\n",
    "print_digit(X.iloc[sample_id])\n",
    "print(\"y[0] : \", y.iloc[sample_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les labels sont représentés par des chaînes de caractères. Pour un traitement plus facile, transformez les en nombres entiers en utilisant la méthode [`astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) de la series `y` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)  # or np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpez votre dataset en un dataset d'entrainement et un dataset de test. Pour réduire le temps de calcul des entrainements suivants, vous pouvez choisir de ne prendre qu'une partie des données pour l'entrainement (30 000 images par exemple) en fournissant un paramètre entier à la fonction [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 30000\n",
    "test_size = 10000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=train_size,test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Classification binaire\n",
    "\n",
    "Pour traiter le cas de la classification binaire, nous considérons le problème de la détection du chiffre $8$. Créez deux series `y_train_8` et `y_test_8` contenant des booléens indiquant si le chiffre est un $8$ ou non :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_8 = (y_train == 8)\n",
    "y_test_8 = (y_test == 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainez un modèle de [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) en recherchant les meilleurs hyper-paramètres par validation croisée avec 3 plis (pour réduire le temps de calcul). Votre grille d'hyper-paramètres pourra se concentrer sur le coefficient de régularisation `C` que vous pouvez faire varier avec `np.logspace(-5, 5, 10)`. Puis affichez les meilleurs hyper-paramètres trouvés.\n",
    "\n",
    "Pensez à centrer et réduire vos données dans un pipeline avec la classe [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "En effet, certains algorithmes d'optimisation de la fonction de coût se comportent mieux quand les données sont standardisées. C'est en particulier le cas des algorithmes de régularisation comme _ridge_, _LASSO_ ou _elastic net_. Par exemple, __[la documentation de scikit-learn pour l'algorithme de régression logistique](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__ précise :\n",
    "\n",
    ">Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 1 pour créer un pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('log_reg', LogisticRegression(solver='saga',\n",
    "                                   tol=0.1,\n",
    "                                   penalty='l2'))\n",
    "])\n",
    "param_grid = [\n",
    "    {'log_reg__C': np.logspace(-5, 5, 10)}\n",
    "]\n",
    "\n",
    "# Alternative 2 pour créer un pipeline\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(solver='saga', tol=0.1))\n",
    "param_grid = [\n",
    "    {'logisticregression__C': np.logspace(-5, 5, 10)}\n",
    "]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=3, scoring=\"accuracy\", verbose=3, n_jobs=10\n",
    ")\n",
    "grid_search.fit(X_train, y_train_8)\n",
    "\n",
    "print(\"Meilleurs hyper-paramètres : \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez l'exactitude (`accuracy`) d'un modèle entrainé avec ces hyper-paramètres sur le jeu d'entrainement avec une validation croisée à 10 plis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(grid_search.best_estimator_, X_train, y_train_8, scoring=\"accuracy\", cv=10)\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la proportion de valeur `True` dans `y_train_8` (donc la proportion de chiffre 8 dans notre dataset d'entrainement). Ce dataset est-il équilibré ? Est-ce que l'exactitude suffit à mesurer la performance d'un modèle sur ce dataset ? Pouvez-vous imaginer un modèle simple pour ce dataset ayant des performances proches du modèle entrainé avec une regression logistique ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (sum(y_train_8.values)/len(y_train_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données est déséquilibré, moins de 10\\% des observations sont des chiffres \"$8$\". Dans ce contexte, l'exactitude n'est pas la mesure de performance la mieux adaptée. Un modèle répondant qu'une image ne correspond jamais à un $8$ aurait une exactitude d'environ 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Mesures de performance\n",
    "\n",
    "### 6.3.1 Matrice de confusion\n",
    "\n",
    "Utilisez la fonction [`sklearn.model_selection.cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) (avec 10 plis) pour récupérer les labels prédits (et non seulement un score) sur une validation croisée. Stockez le résultat dans une variable `y_train_8_pred`, ces résultats nous servirons à mesurer les performances de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_8_pred = cross_val_predict(\n",
    "    grid_search.best_estimator_,\n",
    "    X_train, y_train_8, cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_8_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) pour calculer la matrice de confusion sur ces prédictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train_8, y_train_8_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'affichage obtenu peut-être amélioré avec un graphique, la fonction suivante permet d'afficher un tel graphique. Elle prend en paramètre les trois listes suivantes :\n",
    "* `y_true` : les vérités terrains\n",
    "* `y_pred` : les prédictions\n",
    "* `labels` : les labels à afficher (dans notre cas, vous pouvez utiliser `['non_8', '8']`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ax= plt.subplot()\n",
    "    #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_train_8, y_train_8_pred, ['non_8', '8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Précision, Rappel, score F1\n",
    "\n",
    "Calculez et affichez la précision, le rappel et le score F1 avec les fonctions [`sklearn.metrics.precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) et [`sklearn.metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), puis concluez sur les performances du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Précision : \", precision_score(y_train_8, y_train_8_pred))\n",
    "print(\"Rappel : \", recall_score(y_train_8, y_train_8_pred))\n",
    "print(\"F1 : \", f1_score(y_train_8, y_train_8_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Courbe précision / rappel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des modèles de classification retournent une probabilité d'appartenance à une classe (dans le cas binaire, une probabilité que l'individu soit de la classe $1$, ou que le chiffre soit un $8$ dans notre cas). Les métriques précédentes sont calculées pour un seuil de décision de $0.5$.\n",
    "\n",
    "Affichez une image du dataset et calculez la probabilité que ce soit un $8$ pour notre modèle en utilisant la fonction `predict_proba` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = random.randint(0, len(X_train))\n",
    "print_digit(X_train.iloc[sample_id])\n",
    "print(\n",
    "    \"Probabilités associées aux deux classes : \",\n",
    "    grid_search.best_estimator_.predict_proba([X_train.iloc[sample_id]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score $F_1$ privilégie les modèles avec une précision et un rappel semblables. Selon le contexte, nous pouvons préférer un modèle avec une bonne précision ou un bon rappel. Ainsi, il est intéressant de contrôler le seuil de probabilité utilisé pour prendre la décision.\n",
    "\n",
    "Pour cela, nous avons besoin de récupérer les probabilités associées à chaque individu du jeu d'entrainement. Utilisez la fonction [`sklearn.model_selection.cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) avec 10 plis et le paramètre `method=\"predict_proba\"` pour récupérer ces probabilités. Stockez le résultat dans une variable `y_train_8_scores`. Vous obtiendrez un tableau des probabilités pour les deux classes (non 8 et 8), transformez ce tableau en un tableau de probabilités pour la classe \"est un 8\" `np.array([y[1] for y in y_train_8_scores])` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_8 = y_train_8['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_8_scores = cross_val_predict(\n",
    "    grid_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train_8,\n",
    "    cv=10,\n",
    "    method=\"predict_proba\"\n",
    ")\n",
    "y_train_8_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_8_scores = np.array([y[1] for y in y_train_8_scores])\n",
    "y_train_8_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons faire varier le seuil de désision pour obtenir un meilleur rappel au détriment de la précision (et inversement). Calculez d'abord la précision et le rappel pour différents seuils de décision en utilisant la fonction [`sklearn.metrics.precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, probas = precision_recall_curve(\n",
    "    y_train_8, y_train_8_scores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante affiche un graphique des courbes de précision et rappel en fonction des seuils de décisions possibles, ses paramètres sont les mêmes que la sortie de la fonction `precision_recall_curve` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_proba(precisions, recalls, probas):\n",
    "    plt.plot(probas, precisions[:-1], \"b--\", label=\"Précision\", linewidth=2)\n",
    "    plt.plot(probas, recalls[:-1], \"g-\", label=\"Rappel\", linewidth=2)\n",
    "    plt.xlabel(\"Seuil de probabilité\", fontsize=16)\n",
    "    plt.legend(loc=\"best\", fontsize=16)\n",
    "    plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_proba(precisions, recalls, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi utiliser la fonction suivante pour afficher la précision en fonction du rappel, ce qui nous permet de choisir l'un en fonction de l'autre en fonction de nos objectifs. Ses paramètres sont les précisions et les rappels calculés précédement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Rappel\", fontsize=16)\n",
    "    plt.ylabel(\"Précision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plot_precision_recall(precisions, recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 Courbe ROC\n",
    "\n",
    "La courbe ROC, une autre représentation courante, trace l'évolution du taux des vrais positifs (autrement dit le rappel ou la sensibilité) en fonction du taux de faux positifs (autrement dit $1 - \\text{spécificité}$). La ligne diagonale pointillée correspond à un modèle qui prédit aléatoirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Taux de faux positifs', fontsize=16)\n",
    "    plt.ylabel('Taux de vrais positifs', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, probas = roc_curve(y_train_8, y_train_8_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plot_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Classes multiples\n",
    "\n",
    "Entrainer un modèle _softmax_ avec régularisation _elasticnet_ sur la classification en classes multiples en recherchant les meilleurs hyper-paramètres puis en calculant les performances de ces hyper-paramètres sur le dataset d'entrainement avec une validation croisée à 10 plis.\n",
    "\n",
    "Le modèle _softmax_ est disponible via la classe `LogisticRegression` en utilisant la valeur `multinomial` pour le paramètre `multi_class`. Pour une régularisation _elasticnet_, il faut définir le paramètre `penalty` à `l2`. Vous pouvez aussi utiliser les paramètres `solver='saga'` et `tol=0.1` pour que l'algorithme converge plus rapidement.\n",
    "\n",
    "Calculez l'exactitude de ce modèle et affichez ses prédictions pour quelques invididus de notre jeu d'entrainement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('log_reg', LogisticRegression(multi_class='multinomial',\n",
    "                                   solver='saga',\n",
    "                                   tol=0.1, penalty='l2'))\n",
    "])\n",
    "param_grid = [{'log_reg__C': np.logspace(-5, 5, 5)}]\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid, cv=3,\n",
    "                           scoring=\"f1_weighted\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs hyper-paramètres : \", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(grid_search.best_estimator_, X_train,\n",
    "                         y_train, scoring=\"accuracy\", cv=10)\n",
    "\n",
    "print(\"Moyenne et écart type accuracy : %.4f (%.4f)\" % (scores.mean(),\n",
    "                                                        scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X_train.sample().iloc[0]\n",
    "print_digit(sample)\n",
    "print(\n",
    "    \"Prédiction:\", grid_search.best_estimator_.predict([sample])\n",
    ")\n",
    "print(\n",
    "    \"Probabilités associées à toutes les classes : \",\n",
    "    grid_search.best_estimator_.predict_proba([sample])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Visualisation des poids associés à chaque transformation linéaire du modèle softmax\n",
    "\n",
    "Nous pouvons récupérer poids associés à chaque pixels des images et les afficher pas classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = grid_search.best_estimator_.steps[1][1].coef_\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    plot = plt.subplot(2,5,i+1)\n",
    "    plot.imshow(coef[i].reshape(28,28), cmap=plt.cm.Greys, vmin=-scale, vmax=scale)\n",
    "    plot.set_xticks(())\n",
    "    plot.set_yticks(())\n",
    "    plot.set_xlabel('Classe %i' % i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Visualisation des erreurs\n",
    "\n",
    "La matrice de confusion est toujours utile à analyser. Pour ce problème, vu le nombre important de classes, nous pouvons afficher une version simplifiée de cette matrice :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(grid_search.best_estimator_, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_train, y_train_pred)\n",
    "plt.matshow(confusion, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour y voir plus clair, nous remplaçons la diagonale (les prédictions correctes) par des 0. Nous mettons donc en avant uniqument les cas d'erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(confusion, 0)\n",
    "plt.matshow(confusion, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi afficher aléatoirement un cas d'erreur de notre prédicteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_with_pred = y_train.copy()\n",
    "y_train_with_pred['pred'] = y_train_pred\n",
    "sample = y_train_with_pred[y_train_with_pred[\"class\"] != y_train_with_pred.pred].sample().iloc[0]\n",
    "print(sample.name)\n",
    "print_digit(X_train.loc[sample.name])\n",
    "print(\n",
    "    \"Truth:\", sample['class'],\n",
    "    \"Prediction:\", sample['pred']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Forêt aléatoire\n",
    "\n",
    "Entrainez un modèle de forêt aléatoire sur le problème MNIST puis comparez le modèle obtenu avec le modèle _sortmax_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_jobs=-1,\n",
    "                                  n_estimators=100,\n",
    "                                  random_state=77))\n",
    "])\n",
    "param_grid = {\n",
    "    'rf__max_depth': np.linspace(10,50,5, dtype=int),\n",
    "    'rf__min_samples_leaf': [2,4,8]\n",
    "}\n",
    "grid_search = GridSearchCV(rf_pipeline,\n",
    "                           param_grid, cv=3,\n",
    "                           scoring=\"f1_weighted\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs hyper-paramètres : \", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(grid_search.best_estimator_, X_train,\n",
    "                         y_train, scoring=\"accuracy\", cv=10)\n",
    "\n",
    "print(\"Moyenne et écart type accuracy : %.4f (%.4f)\" % (scores.mean(),\n",
    "                                                        scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf = cross_val_predict(\n",
    "    grid_search.best_estimator_, X_train, y_train, cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_rf = confusion_matrix(y_train, y_train_pred_rf)\n",
    "np.fill_diagonal(confusion_rf, 0)\n",
    "plt.matshow(confusion_rf, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Evaluation du meilleur modèle sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"F1 : \", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
